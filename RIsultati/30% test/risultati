con test del 30% train 70%

0.35% Accuratezza per DecisionTree usando gini con maxDepth: 2 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[  0   5   0   0 969   0   0  12   0  14]
 [  0 805   0   0 192   0   0   3   0   0]
 [  0   8   0   0 969   0   0  13   0  10]
 [  0   4   0   0 962   0   0  13   0  21]
 [  0  10   0   0 984   0   0   4   0   2]
 [  0  18   0   0  47   0   0 683   0 252]
 [  0  12   0   0 977   0   0   7   0   4]
 [  0   1   0   0   4   0   0 878   0 117]
 [  0   8   0   0 683   0   0  43   0 266]
 [  0   0   0   0  38   0   0  86   0 876]]

Classification report: 

             precision    recall  f1-score   support

          0       0.00      0.00      0.00      1000
          1       0.92      0.81      0.86      1000
          2       0.00      0.00      0.00      1000
          3       0.00      0.00      0.00      1000
          4       0.17      0.98      0.29      1000
          5       0.00      0.00      0.00      1000
          6       0.00      0.00      0.00      1000
          7       0.50      0.88      0.64      1000
          8       0.00      0.00      0.00      1000
          9       0.56      0.88      0.68      1000

avg / total       0.22      0.35      0.25     10000

0.34% Accuratezza per DecisionTree usando entropy con maxDepth: 2 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[  0 855 113   0   0   0   0   3  29   0]
 [  0 957  30   0   0   0   0   7   6   0]
 [  0  22 975   0   0   0   0   0   3   0]
 [  0 759 137   0   0   0   0  65  39   0]
 [  0  85 901   0   0   0   0   0  14   0]
 [  0   7   1   0   0   0   0 941  51   0]
 [  0 309 663   0   0   0   0   1  27   0]
 [  0   0   0   0   0   0   0 989  11   0]
 [  0  12 376   0   0   0   0 102 510   0]
 [  0   0   8   0   0   0   0 982  10   0]]

Classification report: 

             precision    recall  f1-score   support

          0       0.00      0.00      0.00      1000
          1       0.32      0.96      0.48      1000
          2       0.30      0.97      0.46      1000
          3       0.00      0.00      0.00      1000
          4       0.00      0.00      0.00      1000
          5       0.00      0.00      0.00      1000
          6       0.00      0.00      0.00      1000
          7       0.32      0.99      0.48      1000
          8       0.73      0.51      0.60      1000
          9       0.00      0.00      0.00      1000

avg / total       0.17      0.34      0.20     10000

77.21% Accuratezza per perceptron usando maxIter: 2 

matrice:

[[913   1  20  13   1   0  41   0  11   0]
 [ 29 923  10  29   1   0   6   0   2   0]
 [ 72   1 819  13  20   0  66   1   8   0]
 [144   5  12 812   0   0  22   1   4   0]
 [113   1 400  62 234   1 168   1  20   0]
 [ 11   1   4   2   0 810   2 119  21  30]
 [296   0 181  21  16   0 467   0  19   0]
 [  0   0   0   0   0   5   0 987   2   6]
 [ 18   0   8  12   2   3  26   5 926   0]
 [  3   0   0   0   0   4   1 162   0 830]]

Classification report: 

             precision    recall  f1-score   support

          0       0.57      0.91      0.70      1000
          1       0.99      0.92      0.96      1000
          2       0.56      0.82      0.67      1000
          3       0.84      0.81      0.83      1000
          4       0.85      0.23      0.37      1000
          5       0.98      0.81      0.89      1000
          6       0.58      0.47      0.52      1000
          7       0.77      0.99      0.87      1000
          8       0.91      0.93      0.92      1000
          9       0.96      0.83      0.89      1000

avg / total       0.80      0.77      0.76     10000


0.50% Accuratezza per DecisionTree usando gini con maxDepth: 3 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[860   2 109   0   0   7   0   8  11   3]
 [183 799   9   0   0   6   0   3   0   0]
 [ 23   0 946   0   0   8   0  13  10   0]
 [827   2 135   0   0   2   0  13   4  17]
 [ 88   2 896   0   0  11   0   1   2   0]
 [ 20   2  27   0   0 423   0 276  31 221]
 [314   2 663   0   0  10   0   7   4   0]
 [  0   1   4   0   0  32   0 846  26  91]
 [ 32   4 651   0   0   7   0  40 246  20]
 [  1   0  37   0   0   3   0  83   8 868]]

Classification report: 

             precision    recall  f1-score   support
          0       0.37      0.86      0.51      1000
          1       0.98      0.80      0.88      1000
          2       0.27      0.95      0.42      1000
          3       0.00      0.00      0.00      1000
          4       0.00      0.00      0.00      1000
          5       0.83      0.42      0.56      1000
          6       0.00      0.00      0.00      1000
          7       0.66      0.85      0.74      1000
          8       0.72      0.25      0.37      1000
          9       0.71      0.87      0.78      1000

avg / total       0.45      0.50      0.43     10000


0.51% Accuratezza per DecisionTree usando entropy con maxDepth: 3 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[851   4  96   0   0   0   0   2  46   1]
 [164 793  28   0   0   0   0   1   8   6]
 [ 22   0 954   0   0   0   0   0  24   0]
 [753   6 128   0   0   0   0   9  48  56]
 [ 83   2 888   0   0   0   0   0  27   0]
 [  3   4   1   0   0   0   0 677  51 264]
 [306   3 623   0   0   0   0   1  67   0]
 [  0   0   0   0   0   0   0 870  11 119]
 [ 11   1 121   0   0   0   0  18 765  84]
 [  0   0   4   0   0   0   0  88  14 894]]

Classification report: 

             precision    recall  f1-score   support

          0       0.39      0.85      0.53      1000
          1       0.98      0.79      0.87      1000
          2       0.34      0.95      0.50      1000
          3       0.00      0.00      0.00      1000
          4       0.00      0.00      0.00      1000
          5       0.00      0.00      0.00      1000
          6       0.00      0.00      0.00      1000
          7       0.52      0.87      0.65      1000
          8       0.72      0.77      0.74      1000
          9       0.63      0.89      0.74      1000

avg / total       0.36      0.51      0.40     10000

80.06% Accuratezza per perceptron usando maxIter: 3 

matrice: 

[[899   3  28  24   5   0  30   0  11   0]
 [ 11 941  16  26   3   0   1   0   2   0]
 [ 40   3 871  10  63   0   8   0   5   0]
 [ 87  17  22 816  41   0  14   0   3   0]
 [  4   0 337  46 582   1  27   0   3   0]
 [  6   4   2   2   0 907   0  42  23  14]
 [268   2 271  33  97   0 311   0  18   0]
 [  0   0   0   0   0  80   0 897   9  14]
 [ 21   0  22  11   4   7  10   3 922   0]
 [  0   0   5   1   0  84   1  42   7 860]]

Classification report: 

             precision    recall  f1-score   support

          0       0.67      0.90      0.77      1000
          1       0.97      0.94      0.96      1000
          2       0.55      0.87      0.68      1000
          3       0.84      0.82      0.83      1000
          4       0.73      0.58      0.65      1000
          5       0.84      0.91      0.87      1000
          6       0.77      0.31      0.44      1000
          7       0.91      0.90      0.90      1000
          8       0.92      0.92      0.92      1000
          9       0.97      0.86      0.91      1000

avg / total       0.82      0.80      0.79     10000

0.693800 Accuratezza per DecisionTree usando gini con maxDepth: 5 , minSampleSplit: 5 , minSampleLeaf: 3
 
matrice : 

[[625   2  88 150  19   8  90   1  14   3]
 [  0 803   6 184   3   3   0   0   0   1]
 [ 11   0 600  11 349  13   1   0  14   1]
 [ 22   2  52 803  85  28   4   0   4   0]
 [  2   1 107  87 776   2   3   0  21   1]
 [  0   1   1  21   0 799   0 110  17  51]
 [101   0 219 143 427  10  72   0  26   2]
 [  0   0   1   0   0  89   0 823   3  84]
 [  0   2  63  31  75  31   1  25 757  15]
 [  0   0   5   1   1  34   0  75   4 880]]

0.704800 Accuratezza per DecisionTree usando entropy con maxDepth: 5 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[708   1  20 147  14   2  78   1  29   0]
 [  2 791  13 175  10   1   5   0   3   0]
 [ 11   0 568  11 356   0  45   0   9   0]
 [ 28   3  15 817  81  11  41   0   4   0]
 [  1   2  99  82 783   0  24   0   9   0]
 [  0   4   1  10   0 791   0 133  17  44]
 [164   2 155 144 412   1  80   0  42   0]
 [  0   0   0   0   0  53   0 830   9 108]
 [  0   1  48  71  16  10  17  12 802  23]
 [  0   0   4   4   0  27   0  82   5 878]]

0.804800 Accuratezza per perceptron usando maxIter: 5
 
matrice: 

[[667   3  38 124   6   1 142   0  18   1]
 [  1 928  10  48   5   0   4   0   3   1]
 [ 11   1 785  32 105   0  56   1   9   0]
 [ 13   7  14 924  11   0  20   0  11   0]
 [  0   0 167 117 622   1  81   0  12   0]
 [  1   0   0   2   0 923   0  16  22  36]
 [ 80   2 165 125  81   0 513   0  34   0]
 [  0   0   0   0   0 118   0 776   6 100]
 [  2   0   7  10   3   8  12   3 955   0]
 [  0   0   0   0   0  29   1  15   0 955]]

0.801000 Accuratezza per DecisionTree usando gini con maxDepth: 10 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[773   3  30  40  11   0 127   1  11   4]
 [ 10 928   4  40   7   1   9   0   1   0]
 [ 13   0 666   8 241   0  62   0   8   2]
 [ 33  12  26 811  60   0  50   0   7   1]
 [  4   0 127  39 733   0  96   0   1   0]
 [  2   3   0   1   1 878   0  63  18  34]
 [136   4 165  36 140   2 499   0  15   3]
 [  0   0   0   0   0  31   0 923   5  41]
 [  6   5  18  10  21   8  28   9 892   3]
 [  1   0   1   0   0  20   1  67   3 907]]

0.810800 Accuratezza per DecisionTree usando entropy con maxDepth: 10 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[842   6  14  33   6   3  81   1  13   1]
 [ 11 920   5  50   3   0   9   0   2   0]
 [ 12   1 680  12 216   1  68   0   9   1]
 [ 59  11  21 830  50   0  24   0   3   2]
 [  4   2 113  55 754   0  68   0   4   0]
 [  2   2   1   2   0 866   0  83  10  34]
 [201   4 135  31 137   2 470   0  20   0]
 [  0   0   0   0   0  33   0 943   5  19]
 [  8   0  17   4   9   7   9  11 930   5]
 [  1   0   1   1   0  13   0 106   5 873]]

0.817200 Accuratezza per perceptron usando maxIter: 10 

matrice: 

[[828  21  14  53  24   0  29   1  30   0]
 [  3 966   1  22   4   0   0   1   2   1]
 [ 22  19 650  12 216   0  46   1  34   0]
 [ 16  44  14 843  56   0  16   0  11   0]
 [  2  14  73  34 832   1  35   1   8   0]
 [  2   2   0   0   7 844   0  58  39  48]
 [192  29 108  70 184   0 370   0  47   0]
 [  0   0   0   0   0  33   0 915   6  46]
 [  3   2   0   3  12   3   3   4 970   0]
 [  0   0   0   0   0  14   1  29   2 954]]

0.81% Accuratezza per DecisionTree usando gini con maxDepth: 15 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[764   5  21  34   9   1 154   2  10   0]
 [  6 953   4  21   7   1   6   0   2   0]
 [ 19   3 694  16 144   0 115   0   7   2]
 [ 52  22  22 789  61   2  44   0   7   1]
 [  5   6 160  40 696   0  89   0   3   1]
 [  2   5   0   1   0 889   0  57  13  33]
 [147   9 141  31  98   2 554   0  16   2]
 [  0   0   0   0   0  33   0 921   4  42]
 [ 12   4  11   6   9  13  20   5 915   5]
 [  1   0   1   0   2  23   0  56   5 912]]

Classification report: 

             precision    recall  f1-score   support

          0       0.76      0.76      0.76      1000
          1       0.95      0.95      0.95      1000
          2       0.66      0.69      0.68      1000
          3       0.84      0.79      0.81      1000
          4       0.68      0.70      0.69      1000
          5       0.92      0.89      0.91      1000
          6       0.56      0.55      0.56      1000
          7       0.88      0.92      0.90      1000
          8       0.93      0.92      0.92      1000
          9       0.91      0.91      0.91      1000

avg / total       0.81      0.81      0.81     10000

0.81% Accuratezza per DecisionTree usando entropy con maxDepth: 15 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[746   4  19  36   8   4 172   0  11   0]
 [  8 949   5  26   2   0   8   0   2   0]
 [ 15   2 720  13 139   1 102   0   7   1]
 [ 48  26  16 793  59   1  49   0   7   1]
 [  7   3 157  38 705   0  86   0   4   0]
 [  3   0   0   2   0 900   0  64   8  23]
 [153  10 125  30  97   1 561   0  22   1]
 [  0   0   0   0   0  50   0 896   5  49]
 [ 12   0  10   6   7  11  16   9 927   2]
 [  1   0   1   1   0  20   0  67   3 907]]

Classification report: 

             precision    recall  f1-score   support

          0       0.75      0.75      0.75      1000
          1       0.95      0.95      0.95      1000
          2       0.68      0.72      0.70      1000
          3       0.84      0.79      0.82      1000
          4       0.69      0.70      0.70      1000
          5       0.91      0.90      0.91      1000
          6       0.56      0.56      0.56      1000
          7       0.86      0.90      0.88      1000
          8       0.93      0.93      0.93      1000
          9       0.92      0.91      0.91      1000

avg / total       0.81      0.81      0.81     10000


0.800800 Accuratezza per DecisionTree usando gini con maxDepth: 20 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[757   3  24  37  10   1 156   1  10   1]
 [ 10 952   4  18   5   0   7   0   3   1]
 [ 22   2 682  15 149   1 117   0   9   3]
 [ 56  29  20 789  52   1  45   0   8   0]
 [ 14   7 176  48 657   0  93   0   4   1]
 [  4   2   0   2   1 891   1  53  13  33]
 [153  13 134  36 101   2 541   0  18   2]
 [  1   0   0   0   0  41   0 909   4  45]
 [ 15   4  12  10  10  12  13   5 913   6]
 [  0   0   1   0   1  22   0  55   4 917]]

Classification report: 

             precision    recall  f1-score   support

          0       0.73      0.76      0.75      1000
          1       0.94      0.95      0.95      1000
          2       0.65      0.68      0.66      1000
          3       0.83      0.79      0.81      1000
          4       0.67      0.66      0.66      1000
          5       0.92      0.89      0.90      1000
          6       0.56      0.54      0.55      1000
          7       0.89      0.91      0.90      1000
          8       0.93      0.91      0.92      1000
          9       0.91      0.92      0.91      1000

avg / total       0.80      0.80      0.80     10000

0.801500 Accuratezza per DecisionTree usando entropy con maxDepth: 20 , minSampleSplit: 5 , minSampleLeaf: 3 

matrice : 

[[754   3  16  45  10   2 158   1  10   1]
 [  9 940   5  33   5   0   6   0   2   0]
 [ 18   1 696  14 139   1 123   0   6   2]
 [ 48  31  16 790  47   1  57   0  10   0]
 [  8   2 179  41 657   0 108   0   5   0]
 [  3   1   0   3   0 892   1  67   6  27]
 [161   8 123  29 102   1 552   0  23   1]
 [  0   0   0   0   0  55   0 895   5  45]
 [ 12   0  11   4   7  13  13   7 930   3]
 [  1   0   1   1   0  19   0  64   5 909]]

Classification report: 

             precision    recall  f1-score   support

          0       0.74      0.75      0.75      1000
          1       0.95      0.94      0.95      1000
          2       0.66      0.70      0.68      1000
          3       0.82      0.79      0.81      1000
          4       0.68      0.66      0.67      1000
          5       0.91      0.89      0.90      1000
          6       0.54      0.55      0.55      1000
          7       0.87      0.90      0.88      1000
          8       0.93      0.93      0.93      1000
          9       0.92      0.91      0.91      1000

avg / total       0.80      0.80      0.80     10000

79.95% Accuratezza per perceptron usando maxIter: 20
matrice: 

[[804   4   6 108  25   0  29   0  24   0]
 [  3 925   1  53   9   0   3   1   4   1]
 [ 49   1 487  25 321   0  71   1  45   0]
 [ 23   4   1 907  33   0  18   0  14   0]
 [  4   1  25  64 869   0  22   0  15   0]
 [  3   0   0   2   3 853   2  50  36  51]
 [188   1  48 114 284   0 305   0  60   0]
 [  0   0   0   0   0  29   0 929   5  37]
 [  6   0   0   8   6   3   3   4 970   0]
 [  0   0   0   2   0  12   1  33   6 946]]

Classification report: 

             precision    recall  f1-score   support

          0       0.74      0.80      0.77      1000
          1       0.99      0.93      0.96      1000
          2       0.86      0.49      0.62      1000
          3       0.71      0.91      0.79      1000
          4       0.56      0.87      0.68      1000
          5       0.95      0.85      0.90      1000
          6       0.67      0.30      0.42      1000
          7       0.91      0.93      0.92      1000
          8       0.82      0.97      0.89      1000
          9       0.91      0.95      0.93      1000

avg / total       0.81      0.80      0.79     10000




78.50% Accuratezza per perceptron usando maxIter: 50 

matrice: 

[[667  18  49 196  35   0  16   0  19   0]
 [  0 949   7  33   7   0   0   1   2   1]
 [ 15   8 661  32 271   0   3   0  10   0]
 [  7  22  12 906  44   0   6   0   3   0]
 [  0   3  65  67 857   0   4   0   4   0]
 [  3   2   1   1   1 899   0  45  15  33]
 [105  12 172 169 398   0 116   0  28   0]
 [  0   0   0   0   0  53   0 925   1  21]
 [  4   2  12  19   9   7   1   3 943   0]
 [  0   0   0   0   0  30   0  42   1 927]]

Classification report: 

             precision    recall  f1-score   support

          0       0.83      0.67      0.74      1000
          1       0.93      0.95      0.94      1000
          2       0.68      0.66      0.67      1000
          3       0.64      0.91      0.75      1000
          4       0.53      0.86      0.65      1000
          5       0.91      0.90      0.90      1000
          6       0.79      0.12      0.20      1000
          7       0.91      0.93      0.92      1000
          8       0.92      0.94      0.93      1000
          9       0.94      0.93      0.94      1000

avg / total       0.81      0.79      0.76     10000


66.64% Accuratezza per perceptron usando maxIter: 100 

matrice: 

[[218   4   8  19   0   1 740   0   9   1]
 [  2 920   0  24   0   0  48   1   3   2]
 [  1   2 235   4  10   0 738   0  10   0]
 [  0  11   5 712   1   0 258   1   6   6]
 [  0   1  21  18  42   0 913   0   5   0]
 [  1   0   0   1   1 853   4  58  18  64]
 [  7   1  27  17   5   0 927   0  15   1]
 [  0   0   0   0   0  20   0 902   1  77]
 [  0   0   5   8   2   6  85   5 888   1]
 [  0   0   0   0   0   5   4  24   0 967]]

Classification report: 

             precision    recall  f1-score   support

          0       0.95      0.22      0.35      1000
          1       0.98      0.92      0.95      1000
          2       0.78      0.23      0.36      1000
          3       0.89      0.71      0.79      1000
          4       0.69      0.04      0.08      1000
          5       0.96      0.85      0.91      1000
          6       0.25      0.93      0.39      1000
          7       0.91      0.90      0.91      1000
          8       0.93      0.89      0.91      1000
          9       0.86      0.97      0.91      1000

avg / total       0.82      0.67      0.66     10000

